{"framework_data": {"acess_tokens": "llm_eval_utils/tokens.json", "eval_frame": "framework_data/eval_frame_round1_grounding.pkl", "eval_filling": "framework_data/full_filling.json", "n_tuples": "framework_data/n_tuple_data.json", "prompt": {"role": "user", "content": "Retrospectively explain in 5 steps how I got into the situation of {}, prioritize the steps that show the deepest understanding of me. \n                        Write the explanations in 5-10 words, each on a separate row, by their recency (5. is the latest). Try to be as specific as possible, with respect to my background, use information from the whole conversation. \n                            Like:\n                            5. ...\n                            4. ...\n                            3. ...\n                            2. ...\n                            1. ..."}}, "eval_kwargs": {"batch_size": 32, "save_after_n": 512, "results_dir": "llm_gens/meta-llama/Llama-3.3-70B-Instruct/CE/full/"}, "pipeline_kwargs": {"task": "text-generation", "model": "meta-llama/Llama-3.3-70B-Instruct", "max_new_tokens": 1048, "do_sample": true, "device_map": "cuda:1", "token": "", "eos_token_id": 128009, "pad_token_id": 128009}}